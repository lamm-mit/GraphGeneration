{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e2670f",
   "metadata": {},
   "source": [
    "# GraphGeneration: Modeling and design of hierarchical bio-inspired de novo spider web structures using deep learning and additive manufacturing \n",
    "\n",
    "## Model 3: Transformer Model - Training and Inference\n",
    "\n",
    "Spider webs are incredible biological structures, comprising thin but strong silk filament and arranged into highly complex hierarchical architectures with striking mechanical properties (e.g., lightweight but high strength).  While simple 2D orb webs can easily be mimicked, the modeling and synthesis of artificial, bio-inspired 3D-based web structures is challenging, partly due to the rich set of design features. Here we use deep learning as a way to model and synthesize such 3D web structures, where generative models are conditioned based on key geometric parameters (incl.: average edge length, number of nodes, average node degree, and others). To identify construction principles, we use inductive representation sampling of large spider web graphs and develop and train three distinct conditional generative models to accomplish this task: 1) An analog diffusion model with sparse neighbor representation, 2) a discrete diffusion model with full neighbor representation, and 3) an autoregressive transformer architecture with full neighbor representation. We find that all three models can produce complex, de novo bio-inspired spider web mimics and successfully construct samples that meet the design conditioning that reflect key geometric features (including, the number of nodes,   spatial orientation, and edge lengths). We further present an algorithm that assembles inductive samples produced by the generative deep learning models into larger-scale structures based on a series of geometric design targets, including helical forms and parametric curves. \n",
    "\n",
    "[1] W. Lu, N.A. Lee, M.J. Buehler, \"Modeling and design of hierarchical bio-inspired de novo spider web structures using deep learning and additive manufacturing,\" PNAS, 120 (31) e2305273120, 2023, \n",
    "https://www.pnas.org/doi/10.1073/pnas.2305273120 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9fcebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    " \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be828131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "    \n",
    "import math\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torchvision\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR\n",
    "from functools import partial, wraps\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric  import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eedaa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe2533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_gpus = torch.cuda.device_count()\n",
    "print(num_of_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Torch version:\", torch.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ccbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params (model):\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "    pytorch_total_params_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print (\"Total parameters: \", pytorch_total_params,\" trainable parameters: \", pytorch_total_params_trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda1d13",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26537c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data.datapipes import functional_transform\n",
    "from torch_geometric.transforms import BaseTransform, LinearTransformation\n",
    "import math\n",
    "import numbers\n",
    "import random\n",
    "from typing import Tuple, Union\n",
    "\n",
    "class RandomRotateDiffusion(BaseTransform):\n",
    "    r\"\"\"Rotates node positions around a specific axis by a randomly sampled\n",
    "    factor within a given interval (functional name: :obj:`random_rotate`).\n",
    "\n",
    "    Args:\n",
    "        degrees (tuple or float): Rotation interval from which the rotation\n",
    "            angle is sampled. If :obj:`degrees` is a number instead of a\n",
    "            tuple, the interval is given by :math:`[-\\mathrm{degrees},\n",
    "            \\mathrm{degrees}]`.\n",
    "        axis (int, optional): The rotation axis. (default: :obj:`0`)\n",
    "    \"\"\"\n",
    "    def __init__(self, degrees: Union[Tuple[float, float], float],\n",
    "                 axis: int = 0):\n",
    "        if isinstance(degrees, numbers.Number):\n",
    "            degrees = (-abs(degrees), abs(degrees))\n",
    "        assert isinstance(degrees, (tuple, list)) and len(degrees) == 2\n",
    "        self.degrees = degrees\n",
    "        self.axis = axis\n",
    "\n",
    "    def __call__(self, pos):\n",
    "        degree = math.pi * random.uniform(*self.degrees) / 180.0\n",
    "        sin, cos = math.sin(degree), math.cos(degree)\n",
    "        \n",
    "        #print (\"Rotation: \", degree*180)\n",
    "\n",
    "        if data.pos.size(-1) == 2:\n",
    "            matrix = [[cos, sin], [-sin, cos]]\n",
    "        else:\n",
    "            if self.axis == 0:\n",
    "                matrix = [[1, 0, 0], [0, cos, sin], [0, -sin, cos]]\n",
    "            elif self.axis == 1:\n",
    "                matrix = [[cos, 0, -sin], [0, 1, 0], [sin, 0, cos]]\n",
    "            else:\n",
    "                matrix = [[cos, sin, 0], [-sin, cos, 0], [0, 0, 1]]\n",
    "        matrix=torch.Tensor (matrix)        \n",
    "       # print (matrix)\n",
    "        pos=  pos @  matrix#.to(pos.device, pos.dtype)\n",
    "        return pos\n",
    "    \n",
    "    #    return LinearTransformationLoc(torch.tensor(matrix))(data)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.degrees}, '\n",
    "                f'axis={self.axis})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef0ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input, y_data,node_number_list,labels_y_txt, max_length , posdim_emb, max_neighbors = torch.load('dataset_webs_many_medium.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (input.shape)\n",
    "print (y_data.shape)\n",
    "print (node_number_list.shape, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5833fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data, node_number_list, degrees=0, jitter=0, clamp_neighbors=True,\n",
    "                enforce_symm=True,):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        self.node_number_list=node_number_list\n",
    "        \n",
    "        self.degrees=degrees\n",
    "        self.jitter=jitter\n",
    "        self.enforce_symm=enforce_symm\n",
    "        \n",
    "        self.randomrotatex= RandomRotateDiffusion (degrees=self.degrees, axis=0)\n",
    "        self.randomrotatey= RandomRotateDiffusion (degrees=self.degrees, axis=1)\n",
    "        self.randomrotatez= RandomRotateDiffusion (degrees=self.degrees, axis=2)\n",
    "        self.clamp_neighbors=clamp_neighbors\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        self.X_data_cl=self.X_data.clone()\n",
    "        resroundL = self.node_number_list [index] #torch.nonzero(self.X_data_cl[index,:,1])[-1]\n",
    "        #print (resroundL)\n",
    "        if self.degrees>0:\n",
    "            #get length of current graph\n",
    "            resroundL = torch.nonzero(self.X_data_cl[index,:,1])[-1]\n",
    "            pos=self.X_data_cl[index,:resroundL,1:4]\n",
    "            #print (pos.shape)\n",
    "            pos =self.randomrotatex(pos)\n",
    "            pos =self.randomrotatey(pos)\n",
    "            pos =self.randomrotatez(pos)\n",
    "            self.X_data_cl[index,:resroundL,1:4]=pos\n",
    "\n",
    "            \n",
    "        if self.jitter >0:\n",
    "\n",
    "            dx=torch.randn(resroundL)*self.jitter \n",
    "            dy=torch.randn(resroundL)*self.jitter \n",
    "            dz=torch.randn(resroundL)*self.jitter \n",
    "            \n",
    "            dx=torch.clamp(dx, min=-self.jitter, max=self.jitter ) \n",
    "            dy=torch.clamp(dy, min=-self.jitter, max=self.jitter ) \n",
    "            dz=torch.clamp(dz, min=-self.jitter, max=self.jitter ) \n",
    "            \n",
    "            self.X_data_cl[index,:resroundL,1]=self.X_data_cl[index,:resroundL,1]+dx\n",
    "            self.X_data_cl[index,:resroundL,2]=self.X_data_cl[index,:resroundL,2]+dy\n",
    "            self.X_data_cl[index,:resroundL,3]=self.X_data_cl[index,:resroundL,3]+dz\n",
    "            \n",
    "        self.X_data_cl[index,resroundL:,:]=0\n",
    "            \n",
    "        dist_matrix=torch.zeros (max_length, max_length)#.to(device)\n",
    "        \n",
    "        for i in range (max_length):\n",
    "             \n",
    "            #neighbors are stored in result [4,5,..., 9]\n",
    "            for j in range (max_neighbors):\n",
    "                \n",
    "                neigh_j=self.X_data_cl[index, i, 4+j] \n",
    "                \n",
    "                if neigh_j !=0: #zeros are padded values...\n",
    "                     \n",
    "                    neighn=  neigh_j.long()\n",
    "\n",
    "                    if self.clamp_neighbors:\n",
    "                        neighn=max( 1, min (neighn, max_length) )\n",
    "                    \n",
    "                    dist_matrix[i, neighn-1] = 1\n",
    "                    if self.enforce_symm:\n",
    "                        \n",
    "                        dist_matrix[neighn-1, i] = 1\n",
    "                    \n",
    "        output=  toranrch.cat( (self.X_data_cl[index,:, :4],   dist_matrix), 1)\n",
    "    \n",
    "        return output, self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "def scale_data(image2, maxv, minv): #(input[:,:,4:10]-X_min_neigh)/(X_max_neigh-X_min_neigh)*2-1\n",
    "    return (image2 -minv)/(maxv-minv) * 2. - 1.0\n",
    " \n",
    "def unscale_data(image2, maxv, minv):\n",
    "    image2=(image2 +1. )/ 2. * (maxv-minv)+minv \n",
    "    return image2\n",
    "\n",
    "\n",
    "def normalize_data (input, y_data, X_min=None, X_max=None, y_min=None, y_max=None,\n",
    "                   \n",
    "                    X_max_neigh=None, X_min_neigh=None,\n",
    "                    Xscale=0):\n",
    "    if X_min==None:\n",
    "        X_min=input[:,:,1:4].min() \n",
    "    else:\n",
    "        print (\"use provided X_min\", X_min)\n",
    "    if X_max==None:\n",
    "        X_max=input[:,:,1:4].max() \n",
    "    else:\n",
    "        print (\"use provided X_max\", X_max)\n",
    "\n",
    "    input[:,:,1:4]=(input[:,:,1:4]-X_min)/(X_max-X_min)*(2-2*Xscale)-(1-Xscale) #Normalize range -1 to 1\n",
    "\n",
    "    if y_min==None:\n",
    "        y_min=[]\n",
    "        for i in range (y_data.shape[1]):\n",
    "            y_min.append(y_data[:,i].min())\n",
    "        \n",
    "    else:\n",
    "        print (\"use provided y_min\", y_min)\n",
    "    if y_max==None:\n",
    "        y_max=[]\n",
    "        for i in range (y_data.shape[1]):\n",
    "            y_max.append(y_data[:,i].max())\n",
    "        \n",
    "    else:\n",
    "        print (\"use provided y_max\", y_max)\n",
    "    for i in range (y_data.shape[1]):\n",
    "        y_data[:,i]=(y_data[:,i]-y_min[i] )/(y_max[i] -y_min[i])*2-1 #Normalize range -1 to 1\n",
    "        \n",
    "    print (\"Check y_data after norm  \", y_data.min(), y_data.max())\n",
    "    return input, y_data, X_min, X_max, y_min, y_max#,X_min_neigh, X_max_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ab6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled, y_data_scaled, X_min, X_max, y_min, y_max = normalize_data (input, y_data,  Xscale=0. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9538e",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_min, X_max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8332ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_min, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8697ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders (X_scaled,  y_data_scaled, node_number_list, split=0.1, batch_size_=16):\n",
    "\n",
    "    X_train, X_test, y_train, y_test, node_number_list_train, node_number_list_test = train_test_split(X_scaled, \n",
    "                                                                                                       y_data_scaled ,\n",
    "                                                                                                       node_number_list,\n",
    "                                                                                                       test_size=split,random_state=235)\n",
    "\n",
    "\n",
    "    print (f\"Shapes= {X_scaled.shape}, {y_data_scaled.shape}\")\n",
    "    \n",
    "     \n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    train_dataset = RegressionDataset(X_train, y_train, node_number_list_train, degrees=0, jitter=0.0,\n",
    "                                     enforce_symm=False) #/ynormfac)\n",
    "\n",
    "    test_dataset = RegressionDataset(X_test,y_test,node_number_list_test, degrees=0, jitter=0.0,\n",
    "                                    enforce_symm=False)\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size_, shuffle=True)\n",
    "    train_loader_noshuffle = DataLoader(dataset=train_dataset, batch_size=batch_size_, shuffle=False)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size_)\n",
    "\n",
    "    return train_loader,train_loader_noshuffle, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba68c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,train_loader_noshuffle, test_loader= get_data_loaders (X_scaled,  y_data_scaled,node_number_list, split=0.1, batch_size_=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b44e81-b277-4a44-a879-c69dbd0c3233",
   "metadata": {},
   "source": [
    "### Build transformer model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on: https://github.com/lucidrains/parti-pytorch\n",
    "\n",
    "from typing import List\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, einsum\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "DEFAULT_T5_NAME=''\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d\n",
    "\n",
    "def eval_decorator(fn):\n",
    "    def inner(model, *args, **kwargs):\n",
    "        was_training = model.training\n",
    "        model.eval()\n",
    "        out = fn(model, *args, **kwargs)\n",
    "        model.train(was_training)\n",
    "        return out\n",
    "    return inner\n",
    "\n",
    "# sampling helpers\n",
    "\n",
    "def log(t, eps = 1e-20):\n",
    "    return torch.log(t + eps)\n",
    "\n",
    "def gumbel_noise(t):\n",
    "    noise = torch.zeros_like(t).uniform_(0, 1)\n",
    "    return -log(-log(noise))\n",
    "\n",
    "def gumbel_sample(t, temperature = 1., dim = -1):\n",
    "    return ((t / temperature) + gumbel_noise(t)).argmax(dim = dim)\n",
    "\n",
    "def top_k(logits, thres = 0.5):\n",
    "    num_logits = logits.shape[-1]\n",
    "    k = max(int((1 - thres) * num_logits), 1)\n",
    "    val, ind = torch.topk(logits, k)\n",
    "    probs = torch.full_like(logits, float('-inf'))\n",
    "    probs.scatter_(1, ind, val)\n",
    "    return probs\n",
    "\n",
    "# classifier free guidance functions\n",
    "\n",
    "def prob_mask_like(shape, prob, device):\n",
    "    if prob == 1:\n",
    "        return torch.ones(shape, device = device, dtype = torch.bool)\n",
    "    elif prob == 0:\n",
    "        return torch.zeros(shape, device = device, dtype = torch.bool)\n",
    "    else:\n",
    "        return torch.zeros(shape, device = device).float().uniform_(0, 1) < prob\n",
    "\n",
    "# normalization\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(dim))\n",
    "        self.register_buffer('beta', torch.zeros(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.layer_norm(x, x.shape[-1:], self.gamma, self.beta)\n",
    "\n",
    "# 2d relative positional bias\n",
    "\n",
    "class RelPosBias2d(nn.Module):\n",
    "    def __init__(self, size, heads):\n",
    "        super().__init__()\n",
    "        self.pos_bias = nn.Embedding((2 * size - 1) ** 2, heads)\n",
    "\n",
    "        arange = torch.arange(size)\n",
    "\n",
    "        pos = torch.stack(torch.meshgrid(arange, arange, indexing = 'ij'), dim = -1)\n",
    "        pos = rearrange(pos, '... c -> (...) c')\n",
    "        rel_pos = rearrange(pos, 'i c -> i 1 c') - rearrange(pos, 'j c -> 1 j c')\n",
    "\n",
    "        rel_pos = rel_pos + size - 1\n",
    "        h_rel, w_rel = rel_pos.unbind(dim = -1)\n",
    "        pos_indices = h_rel * (2 * size - 1) + w_rel\n",
    "        self.register_buffer('pos_indices', pos_indices)\n",
    "\n",
    "    def forward(self, qk):\n",
    "        i, j = qk.shape[-2:]\n",
    "\n",
    "        bias = self.pos_bias(self.pos_indices[:i, :(j - 1)])\n",
    "        bias = rearrange(bias, 'i j h -> h i j')\n",
    "\n",
    "        bias = F.pad(bias, (j - bias.shape[-1], 0), value = 0.) # account for null key / value for classifier free guidance\n",
    "        return bias\n",
    "\n",
    "# feedforward\n",
    "\n",
    "def FeedForward(dim, mult = 4, dropout = 0.):\n",
    "    dim_hidden = int(dim * mult)\n",
    "    return nn.Sequential(\n",
    "        LayerNorm(dim),\n",
    "        nn.Linear(dim, dim_hidden, bias = False),\n",
    "        nn.GELU(),\n",
    "        LayerNorm(dim_hidden),\n",
    "        nn.Linear(dim_hidden, dim, bias = False)\n",
    "    )\n",
    "\n",
    "# attention\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        *,\n",
    "        context_dim = None,\n",
    "        dim_head = 64,\n",
    "        heads = 8,\n",
    "        causal = False,\n",
    "        dropout = 0.,\n",
    "        norm_context = False,\n",
    "        rel_pos_bias = False,\n",
    "        encoded_fmap_size = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.causal = causal\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "        inner_dim = heads * dim_head\n",
    "        context_dim = default(context_dim, dim)\n",
    "        self.norm_context = LayerNorm(context_dim) if norm_context else nn.Identity()\n",
    "\n",
    "        self.to_q = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim, inner_dim, bias = False),\n",
    "            Rearrange('b n (h d) -> b h n d', h = heads)\n",
    "        )\n",
    "\n",
    "        # needed for classifier free guidance for transformers\n",
    "        # by @crowsonkb, adopted by the paper\n",
    "\n",
    "        self.null_kv = nn.Parameter(torch.randn(dim_head))\n",
    "\n",
    "        # one-headed key / value attention, from Shazeer's multi-query paper, adopted by Alphacode and PaLM\n",
    "\n",
    "        self.to_kv = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(context_dim, dim_head, bias = False)\n",
    "        )\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            Rearrange('b h n d -> b n (h d)'),\n",
    "            nn.Linear(inner_dim, dim, bias = False),\n",
    "            LayerNorm(dim)\n",
    "        )\n",
    "\n",
    "        # positional bias\n",
    "\n",
    "        self.rel_pos_bias = None\n",
    "\n",
    "        if rel_pos_bias:\n",
    "            assert exists(encoded_fmap_size)\n",
    "            self.rel_pos_bias = RelPosBias2d(encoded_fmap_size, heads)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        context = None,\n",
    "        context_mask = None\n",
    "    ):\n",
    "        batch, device = x.shape[0], x.device\n",
    "\n",
    "        x = self.norm(x)\n",
    "\n",
    "        q = self.to_q(x) * self.scale\n",
    "\n",
    "        context = default(context, x)\n",
    "        context = self.norm_context(context)\n",
    "\n",
    "        kv = self.to_kv(context)\n",
    "\n",
    "        null_kv = repeat(self.null_kv, 'd -> b 1 d', b = batch)\n",
    "        kv = torch.cat((null_kv, kv), dim = 1)\n",
    "\n",
    "        sim = einsum('b h i d, b j d -> b h i j', q, kv)\n",
    "\n",
    "        if exists(self.rel_pos_bias):\n",
    "            pos_bias = self.rel_pos_bias(sim)\n",
    "            sim = sim + pos_bias\n",
    "\n",
    "        mask_value = -torch.finfo(sim.dtype).max\n",
    "\n",
    "        if exists(context_mask):\n",
    "            context_mask = F.pad(context_mask, (1, 0), value = True)\n",
    "            context_mask = rearrange(context_mask, 'b j -> b 1 1 j')\n",
    "            sim = sim.masked_fill(~context_mask, mask_value)\n",
    "\n",
    "        if self.causal:\n",
    "            i, j = sim.shape[-2:]\n",
    "            causal_mask = torch.ones((i, j), dtype = torch.bool, device = device).triu(j - i + 1)\n",
    "            sim = sim.masked_fill(causal_mask, mask_value)\n",
    "\n",
    "        attn = sim.softmax(dim = -1, dtype = torch.float32)\n",
    "        out = einsum('b h i j, b j d -> b h i d', attn, kv)\n",
    "\n",
    "        return self.to_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf289d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/tatp22/multidim-positional-encoding/blob/master/positional_encodings/positional_encodings.py\n",
    "\n",
    "class PositionalEncoding1D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        :param channels: The last dimension of the tensor you want to apply pos emb to.\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding1D, self).__init__()\n",
    "        self.org_channels = channels\n",
    "        channels = int(np.ceil(channels / 2) * 2)\n",
    "        self.channels = channels\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, channels, 2).float() / channels))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        \"\"\"\n",
    "        :param tensor: A 3d tensor of size (batch_size, x, ch)\n",
    "        :return: Positional Encoding Matrix of size (batch_size, x, ch)\n",
    "        \"\"\"\n",
    "        if len(tensor.shape) != 3:\n",
    "            raise RuntimeError(\"The input tensor has to be 3d!\")\n",
    "        batch_size, x, orig_ch = tensor.shape\n",
    "        pos_x = torch.arange(x, device=tensor.device).type(self.inv_freq.type())\n",
    "        sin_inp_x = torch.einsum(\"i,j->ij\", pos_x, self.inv_freq)\n",
    "        emb_x = torch.cat((sin_inp_x.sin(), sin_inp_x.cos()), dim=-1)\n",
    "        emb = torch.zeros((x, self.channels), device=tensor.device).type(tensor.type())\n",
    "        emb[:, : self.channels] = emb_x\n",
    "\n",
    "        return emb[None, :, :orig_ch].repeat(batch_size, 1, 1)\n",
    "\n",
    "\n",
    "class PositionalEncodingPermute1D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        Accepts (batchsize, ch, x) instead of (batchsize, x, ch)\n",
    "        \"\"\"\n",
    "        super(PositionalEncodingPermute1D, self).__init__()\n",
    "        self.penc = PositionalEncoding1D(channels)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        tensor = tensor.permute(0, 2, 1)\n",
    "        enc = self.penc(tensor)\n",
    "        return enc.permute(0, 2, 1)\n",
    "\n",
    "    @property\n",
    "    def org_channels(self):\n",
    "        return self.penc.org_channels\n",
    "\n",
    "class PositionalEncoding2D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        :param channels: The last dimension of the tensor you want to apply pos emb to.\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding2D, self).__init__()\n",
    "        self.org_channels = channels\n",
    "        channels = int(np.ceil(channels / 4) * 2)\n",
    "        self.channels = channels\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, channels, 2).float() / channels))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        \"\"\"\n",
    "        :param tensor: A 4d tensor of size (batch_size, x, y, ch)\n",
    "        :return: Positional Encoding Matrix of size (batch_size, x, y, ch)\n",
    "        \"\"\"\n",
    "        if len(tensor.shape) != 4:\n",
    "            raise RuntimeError(\"The input tensor has to be 4d!\")\n",
    "        batch_size, x, y, orig_ch = tensor.shape\n",
    "        pos_x = torch.arange(x, device=tensor.device).type(self.inv_freq.type())\n",
    "        pos_y = torch.arange(y, device=tensor.device).type(self.inv_freq.type())\n",
    "        sin_inp_x = torch.einsum(\"i,j->ij\", pos_x, self.inv_freq)\n",
    "        sin_inp_y = torch.einsum(\"i,j->ij\", pos_y, self.inv_freq)\n",
    "        emb_x = torch.cat((sin_inp_x.sin(), sin_inp_x.cos()), dim=-1).unsqueeze(1)\n",
    "        emb_y = torch.cat((sin_inp_y.sin(), sin_inp_y.cos()), dim=-1)\n",
    "        emb = torch.zeros((x, y, self.channels * 2), device=tensor.device).type(\n",
    "            tensor.type()\n",
    "        )\n",
    "        emb[:, :, : self.channels] = emb_x\n",
    "        emb[:, :, self.channels : 2 * self.channels] = emb_y\n",
    "\n",
    "        return emb[None, :, :, :orig_ch].repeat(tensor.shape[0], 1, 1, 1)\n",
    "\n",
    "class PositionalEncodingPermute2D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        Accepts (batchsize, ch, x, y) instead of (batchsize, x, y, ch)\n",
    "        \"\"\"\n",
    "        super(PositionalEncodingPermute2D, self).__init__()\n",
    "        self.penc = PositionalEncoding2D(channels)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        tensor = tensor.permute(0, 2, 3, 1)\n",
    "        enc = self.penc(tensor)\n",
    "        return enc.permute(0, 3, 1, 2)\n",
    "\n",
    "    @property\n",
    "    def org_channels(self):\n",
    "        return self.penc.org_channels\n",
    "\n",
    "class PositionalEncoding3D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        :param channels: The last dimension of the tensor you want to apply pos emb to.\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding3D, self).__init__()\n",
    "        self.org_channels = channels\n",
    "        channels = int(np.ceil(channels / 6) * 2)\n",
    "        if channels % 2:\n",
    "            channels += 1\n",
    "        self.channels = channels\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, channels, 2).float() / channels))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        \"\"\"\n",
    "        :param tensor: A 5d tensor of size (batch_size, x, y, z, ch)\n",
    "        :return: Positional Encoding Matrix of size (batch_size, x, y, z, ch)\n",
    "        \"\"\"\n",
    "        if len(tensor.shape) != 5:\n",
    "            raise RuntimeError(\"The input tensor has to be 5d!\")\n",
    "        batch_size, x, y, z, orig_ch = tensor.shape\n",
    "        pos_x = torch.arange(x, device=tensor.device).type(self.inv_freq.type())\n",
    "        pos_y = torch.arange(y, device=tensor.device).type(self.inv_freq.type())\n",
    "        pos_z = torch.arange(z, device=tensor.device).type(self.inv_freq.type())\n",
    "        sin_inp_x = torch.einsum(\"i,j->ij\", pos_x, self.inv_freq)\n",
    "        sin_inp_y = torch.einsum(\"i,j->ij\", pos_y, self.inv_freq)\n",
    "        sin_inp_z = torch.einsum(\"i,j->ij\", pos_z, self.inv_freq)\n",
    "        emb_x = (\n",
    "            torch.cat((sin_inp_x.sin(), sin_inp_x.cos()), dim=-1)\n",
    "            .unsqueeze(1)\n",
    "            .unsqueeze(1)\n",
    "        )\n",
    "        emb_y = torch.cat((sin_inp_y.sin(), sin_inp_y.cos()), dim=-1).unsqueeze(1)\n",
    "        emb_z = torch.cat((sin_inp_z.sin(), sin_inp_z.cos()), dim=-1)\n",
    "        emb = torch.zeros((x, y, z, self.channels * 3), device=tensor.device).type(\n",
    "            tensor.type()\n",
    "        )\n",
    "        emb[:, :, :, : self.channels] = emb_x\n",
    "        emb[:, :, :, self.channels : 2 * self.channels] = emb_y\n",
    "        emb[:, :, :, 2 * self.channels :] = emb_z\n",
    "\n",
    "        return emb[None, :, :, :, :orig_ch].repeat(batch_size, 1, 1, 1, 1)\n",
    "\n",
    "\n",
    "class PositionalEncodingPermute3D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        Accepts (batchsize, ch, x, y, z) instead of (batchsize, x, y, z, ch)\n",
    "        \"\"\"\n",
    "        super(PositionalEncodingPermute3D, self).__init__()\n",
    "        self.penc = PositionalEncoding3D(channels)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        tensor = tensor.permute(0, 2, 3, 4, 1)\n",
    "        enc = self.penc(tensor)\n",
    "        return enc.permute(0, 4, 1, 2, 3)\n",
    "\n",
    "    @property\n",
    "    def org_channels(self):\n",
    "        return self.penc.org_channels\n",
    "\n",
    "class FixEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    :param pos_encoder: instance of PositionalEncoding1D, PositionalEncoding2D or PositionalEncoding3D\n",
    "    :param shape: shape of input, excluding batch and embedding size\n",
    "    Example:\n",
    "    p_enc_2d = FixEncoding(PositionalEncoding2D(32), (x, y)) # for where x and y are the dimensions of your image\n",
    "    inputs = torch.randn(64, 128, 128, 32) # where x and y are 128, and 64 is the batch size\n",
    "    p_enc_2d(inputs)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pos_encoder, shape):\n",
    "        super(FixEncoding, self).__init__()\n",
    "        self.shape = shape\n",
    "        self.dim = len(shape)\n",
    "        self.pos_encoder = pos_encoder\n",
    "        self.pos_encoding = pos_encoder(\n",
    "            torch.ones(1, *shape, self.pos_encoder.org_channels)\n",
    "        )\n",
    "        self.batch_size = 0\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        if self.batch_size != tensor.shape[0]:\n",
    "            self.repeated_pos_encoding = self.pos_encoding.to(tensor.device).repeat(\n",
    "                tensor.shape[0], *(self.dim + 1) * [1]\n",
    "            )\n",
    "            self.batch_size = tensor.shape[0]\n",
    "        return self.repeated_pos_encoding    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddEncDec(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "            embed_dim_neighbor=6,\n",
    "            neigh_emb_trainable=False,\n",
    "            max_norm=1.,#embedding ayer mnormed\n",
    "            norm_type=2.,\n",
    "            max_length=1024,\n",
    "            max_neighbors=5,\n",
    "        \n",
    "            \n",
    "         \n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim_neighbor=embed_dim_neighbor\n",
    "        self.max_neighbors=max_neighbors\n",
    "        self.neigh_embs=nn.Embedding(max_length+1, self.embed_dim_neighbor, padding_idx=0, max_norm=max_norm, norm_type =norm_type) \n",
    "      \n",
    "        self.neigh_embs.requires_grad = neigh_emb_trainable     \n",
    "    def encode(self, output_neighbors, plot_hist=False):\n",
    "        \n",
    "        \n",
    "        for i  in range (self.max_neighbors):\n",
    "            x_neigh_l=output_neighbors[:,i,:] \n",
    "           \n",
    "            x_neigh_l = torch.unsqueeze(x_neigh_l, dim=-1)\n",
    "            \n",
    "            x_cc =  self.neigh_embs(x_neigh_l)#.to(device=device)\n",
    "\n",
    "            x_cc = torch.squeeze(x_cc, 2)\n",
    "            x_cc=torch.permute(x_cc, (0,2,1)  )\n",
    "            \n",
    "            if i==0:\n",
    "                output= x_cc#torch.cat( (output_xyz, x_cc  ), 1)\n",
    "                \n",
    "            else:    \n",
    "                output= torch.cat( (output, x_cc ), 1)\n",
    "                \n",
    "        if plot_hist:\n",
    "            sns.set_style(\"whitegrid\")\n",
    "            fig=sns.histplot(output.detach().numpy().flatten() ,bins=100,  )\n",
    "            fig.set_xlabel( \"Embedding values\", fontsize = 10 )\n",
    "             \n",
    "            plt.show()\n",
    "        return output\n",
    "    \n",
    "    def decode(self, output):\n",
    "        ind_list=[]\n",
    "       \n",
    "        for i  in range (self.max_neighbors):\n",
    "             \n",
    "            ll=self.embed_dim_neighbor\n",
    "            \n",
    "            out=output[:,i*ll:(i+1)*ll ]\n",
    "         \n",
    "            out=torch.permute(out, (0,2,1)  )\n",
    "            \n",
    "            indices=invert_embedding (out, self.neigh_embs )\n",
    "           \n",
    "            t=torch.Tensor (indices)\n",
    "           \n",
    "            if i==0:\n",
    "                ind_list=t.unsqueeze (1)\n",
    "            else:\n",
    "                ind_list=torch.cat((ind_list, t.unsqueeze (1)), 1)\n",
    "        return ind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e94651",
   "metadata": {},
   "outputs": [],
   "source": [
    "EncDec=EmbeddEncDec( embed_dim_neighbor=3,\n",
    "            neigh_emb_trainable=False,\n",
    "            max_norm=True,\n",
    "            max_length=max_length,\n",
    "            max_neighbors=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb38d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes\n",
    "def pad_sequence (output_xyz, max_length):         #pad\n",
    "    output=torch.zeros((output_xyz.shape[0],  output_xyz.shape[1] , max_length)).to(device)\n",
    "    output[:,:,:output_xyz.shape[2]]=output_xyz #just positions for now....\n",
    "    return output\n",
    "\n",
    "class GraphWebTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        depth,\n",
    "        dim_head = 64,\n",
    "        heads = 8,\n",
    "        dropout = 0.,\n",
    "        ff_mult = 4,\n",
    "        #position_dim_graph=16,\n",
    "        \n",
    "        max_length=1024,\n",
    "        \n",
    "        embed_dim_position=64,\n",
    "        embed_dim_neighbor=6,\n",
    "        \n",
    "        neigh_emb_trainable=False,\n",
    "        max_norm=1., \n",
    "            \n",
    "        predict_neighbors=True, \n",
    "        \n",
    "        pos_fourier_graph_dim=128, \n",
    "        \n",
    "        pos_emb_fourier=True,\n",
    "        pos_emb_fourier_add=False,\n",
    "      \n",
    "        text_embed_dim = 128,\n",
    "        cond_drop_prob = 0.25,\n",
    "        max_text_len = 128,\n",
    "        max_neighbors=5,\n",
    "        \n",
    "        use_categorical_for_neighbors = False, #if False, use fixed embeddings and MSE\n",
    "        \n",
    "        predict_distance_matrix=False,#if True predict positions and distance matrix\n",
    "        \n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.predict_distance_matrix=predict_distance_matrix\n",
    "        \n",
    "        if predict_distance_matrix:\n",
    "            predict_neighbors=False #predict just one slab... no embeddigs etc\n",
    "        self.pos_emb_fourier=pos_emb_fourier\n",
    "        self.pos_emb_fourier_add=pos_emb_fourier_add\n",
    "        self.embed_dim_neighbor=embed_dim_neighbor\n",
    "        self.predict_neighbors=predict_neighbors\n",
    "        self.pos_fourier_graph_dim=pos_fourier_graph_dim\n",
    "        self.use_categorical_for_neighbors=use_categorical_for_neighbors\n",
    "        self.max_neighbors=max_neighbors\n",
    "        \n",
    "        \n",
    "        self.neigh_emb_trainable=neigh_emb_trainable \n",
    "        #################################################\n",
    "        # text conditioning\n",
    "        self.fc1 = nn.Linear( 1,  text_embed_dim)  # INPUT DIM (last), OUTPUT DIM, last\n",
    "        \n",
    "        self.GELUact= nn.GELU()\n",
    "        if self.pos_emb_fourier:\n",
    "            if self.pos_emb_fourier_add==False:\n",
    "                text_embed_dim=text_embed_dim+embed_dim_position\n",
    "            if self.pos_emb_fourier_add:\n",
    "                print (\"Add pos encoding... \", text_embed_dim, embed_dim_position)\n",
    "                \n",
    "            self.p_enc_1d = PositionalEncoding1D(embed_dim_position)    \n",
    "            \n",
    "        self.max_text_len = max_text_len\n",
    "        #################################################\n",
    "         \n",
    "        self.max_length=max_length \n",
    "        \n",
    "        self.max_tokens = max_length+1 #there are as many tokens as there is length in a graph\n",
    "        if self.predict_neighbors:\n",
    "\n",
    "            if not self.neigh_emb_trainable:\n",
    "                self.neigh_embs=nn.Embedding(self.max_tokens, #this is neighbor types we can have .. i.e. equatl to number of nodes                                       \n",
    "                                                    #self.embed_dim_neighbor, padding_idx=0, max_norm=max_norm, norm_type =2) \n",
    "                                                    self.embed_dim_neighbor,  max_norm=max_norm, norm_type =2) \n",
    "                \n",
    "                #not trainable\n",
    "                #self.neigh_embs.requires_grad = neigh_emb_trainable \n",
    "                self.neigh_embs.weight.requires_grad = neigh_emb_trainable \n",
    "            else:\n",
    "                self.neigh_embs=nn.Embedding(self.max_tokens, #this is neighbor types we can have .. i.e. equatl to number of nodes                                       \n",
    "                                                    #self.embed_dim_neighbor, padding_idx=0 ) \n",
    "                                                    self.embed_dim_neighbor  ) \n",
    "            \n",
    "        #######################\n",
    "        # prediction of graphs\n",
    "        self.pred_dim=3+self.max_neighbors*self.predict_neighbors*embed_dim_neighbor+self.predict_distance_matrix *self.max_length\n",
    "        if predict_distance_matrix:\n",
    "            predict_neighbors=False #predict just one slab... no embeddigs etc\n",
    "        \n",
    "        if self.use_categorical_for_neighbors:\n",
    "            self.logits_dim=  3+self.max_neighbors*self.max_tokens\n",
    "            self.xyz_and_neigbor_dim = 3+self.max_neighbors\n",
    "            # if use categorical loss for neighbors then pred_dim is 3+ one hot encoding of neighbors X max_neighbors\n",
    "        else:\n",
    "            self.logits_dim=self.pred_dim #if use MSE loss pred_dim is 3+embeddig of beighbors\n",
    "            self.xyz_and_neigbor_dim = self.pred_dim\n",
    "            \n",
    "    \n",
    "        self.p_enc_1d_graph = PositionalEncodingPermute1D(self.pos_fourier_graph_dim)    \n",
    "            \n",
    "        self.start_token = nn.Parameter (torch.randn(self.pred_dim+self.pos_fourier_graph_dim))\n",
    "        print (\"Internal pred dim: \", self.pred_dim, \"Four graph enc dim: \", pos_fourier_graph_dim,\n",
    "              \"Logits dim: \", self.logits_dim)\n",
    "\n",
    "    \n",
    "        assert cond_drop_prob > 0.\n",
    "        self.cond_drop_prob = cond_drop_prob # classifier free guidance for transformers - @crowsonkb\n",
    "\n",
    "        # projecting to logits\n",
    "\n",
    "        self.init_norm = LayerNorm(dim)\n",
    "\n",
    "        self.layers = nn.ModuleList([])\n",
    "\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                #Attention(dim, causal = True, encoded_fmap_size = self.image_encoded_dim, rel_pos_bias = True, \n",
    "                #          dim_head = dim_head, heads = heads, dropout = dropout),\n",
    "                Attention(dim, causal = True, rel_pos_bias = False, \n",
    "                          dim_head = dim_head, heads = heads, dropout = dropout),\n",
    "                \n",
    "                Attention(dim, context_dim = text_embed_dim, dim_head = dim_head, heads = heads, dropout = dropout),\n",
    "                FeedForward(dim, mult = ff_mult, dropout = dropout)\n",
    "            ]))\n",
    "\n",
    "        self.final_norm = LayerNorm(dim)\n",
    "\n",
    "        self.to_logits = nn.Linear(dim, self.logits_dim, bias = False)\n",
    "        \n",
    "        self.to_dim = nn.Linear( self.pred_dim+self.pos_fourier_graph_dim, dim, bias = False)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    @eval_decorator\n",
    "    def generate(\n",
    "        self,\n",
    "        sequences=None,#conditioning\n",
    "        *,\n",
    "        cond_scale = 3.,\n",
    "        text_mask=None,\n",
    "        filter_thres = 0.9,\n",
    "         temperature = 1.,\n",
    "        tokens_to_generate=None,\n",
    "        use_argmax=True,#True= use argmax, otherwise gumbel\n",
    "         \n",
    "    ):\n",
    "        device = next(self.parameters()).device\n",
    "      \n",
    "\n",
    "        if not exists(text_mask):\n",
    "            text_mask = torch.ones(sequences.shape[:2], dtype = torch.bool).to(device)\n",
    "\n",
    "        \n",
    "        \n",
    "         \n",
    "        batch = sequences.shape[0]\n",
    "        if not exists (tokens_to_generate):\n",
    "            image_seq_len =self.max_length #just set to max length...\n",
    "        else:\n",
    "            image_seq_len=tokens_to_generate\n",
    "\n",
    "        output = torch.empty((batch, self.xyz_and_neigbor_dim, 0), device = device )\n",
    "        \n",
    "        \n",
    "        if self.use_categorical_for_neighbors:\n",
    "            \n",
    "        \n",
    "            for j in tqdm( range(image_seq_len) ):\n",
    "                \n",
    "              \n",
    "                logits  = self.forward_with_cond_scale(\n",
    "                    sequences = sequences,\n",
    "                    text_mask = text_mask,\n",
    "                    output = output,\n",
    "                    shift_input_depth=0,#usually is one when original training input is used\n",
    "                )[:, :, -1]\n",
    "                \n",
    "               \n",
    "                xyz_logits= logits[:,:3] \n",
    "             \n",
    "                for i in range ( self.max_neighbors ):\n",
    "                    neighbor_logits_i=logits[:,\n",
    "                                           3+i*self.max_tokens:3+(i+1)*self.max_tokens\n",
    "                                           ]\n",
    "                   \n",
    "                    if not use_argmax:\n",
    "\n",
    "                       \n",
    "                        filtered_logits = top_k(neighbor_logits_i, thres = filter_thres)\n",
    "\n",
    "                        \n",
    "                        sampled = gumbel_sample(filtered_logits, temperature = temperature, dim = -1)\n",
    "                  \n",
    "\n",
    "                    else:\n",
    "                        sampled=torch.argmax (neighbor_logits_i, -1)\n",
    "                     \n",
    "                    sampled = rearrange(sampled, 'b -> b 1 ')\n",
    "                    \n",
    "                    \n",
    "                    if i==0:\n",
    "                        output = torch.cat((xyz_logits, sampled), dim = -1)\n",
    "                    else:\n",
    "                        output = torch.cat((output, sampled), dim = -1)\n",
    "                output=output.unsqueeze(2)   \n",
    "                \n",
    "                if j==0:\n",
    "                    output_f=output\n",
    "                if j>0:\n",
    "                    output_f=torch.cat((output_f, output), dim = -1)\n",
    "                    \n",
    "           \n",
    "            return output_f\n",
    "                \n",
    "    \n",
    "        if not self.use_categorical_for_neighbors:\n",
    "\n",
    "           \n",
    "            for _ in tqdm( range(image_seq_len) ):\n",
    "                sampled = self.forward_with_cond_scale(\n",
    "        \n",
    "                    sequences = sequences,\n",
    "                    text_mask = text_mask,\n",
    "                    output = output,\n",
    "                    encode_graphs=False,# we are looping with encoded data\n",
    "                    shift_input_depth=0,\n",
    "                )\n",
    "              \n",
    "                sampled=sampled[:, :, -1]#take LAST prediction....\n",
    "\n",
    "             \n",
    "                sampled = rearrange(sampled, 'b c -> b c 1')\n",
    "            \n",
    "                output = torch.cat((output, sampled), dim = -1)\n",
    "\n",
    "\n",
    "            if self.predict_neighbors: \n",
    "                ind_list=[]\n",
    "              \n",
    "                for i  in range (self.max_neighbors):\n",
    "\n",
    "                    ll=self.embed_dim_neighbor\n",
    "\n",
    "                    out=output[:,3+i*ll:3+(i+1)*ll ]\n",
    "                   \n",
    "                    out=torch.permute(out, (0,2,1)  )\n",
    "            \n",
    "                    indices=invert_embedding (out, self.neigh_embs )\n",
    "                 \n",
    "                    t=torch.Tensor (indices)\n",
    "                 \n",
    "                    if i==0:\n",
    "                        ind_list=t.unsqueeze (1)\n",
    "                    else:\n",
    "                        ind_list=torch.cat((ind_list, t.unsqueeze (1)), 1) \n",
    "\n",
    "                \n",
    "                output=torch.cat((output[:,0:3,:], ind_list.to(device) ), 1) \n",
    "\n",
    "            return output         \n",
    "    def forward_with_cond_scale(self, *args, cond_scale = 3, **kwargs):\n",
    "    \n",
    "        logits = self.forward(*args, cond_drop_prob = 0., **kwargs)\n",
    "     \n",
    "        if cond_scale == 1:\n",
    "            return logits\n",
    "\n",
    "        null_logits = self.forward(*args, cond_drop_prob = 1., **kwargs)\n",
    "        \n",
    "        return null_logits + (logits - null_logits) * cond_scale\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        sequences=None,#conditioning\n",
    "        output=None,\n",
    "        text_mask = None,\n",
    "        cond_drop_prob = None,\n",
    "        \n",
    "        return_loss = False,\n",
    "        shift_input_depth=1, #since first deppth is 1,2,3,4,5... \n",
    "        encode_graphs=True, #set to False when generationgng \n",
    "         \n",
    "        \n",
    "        \n",
    "    ):\n",
    "        \n",
    "        cond_drop_prob = default(cond_drop_prob, self.cond_drop_prob)\n",
    "\n",
    "        \n",
    "        ########################## conditioning #################################### \n",
    "        \n",
    "        cond_x=sequences.float().unsqueeze(2)\n",
    "        \n",
    "        cond_x= self.fc1(cond_x)\n",
    "        \n",
    "        \n",
    "        cond_x=self.GELUact(cond_x) \n",
    "        \n",
    "       \n",
    "        if self.pos_emb_fourier:\n",
    "           \n",
    "            pos_fourier_xy=self.p_enc_1d(cond_x) \n",
    "          \n",
    "            if self.pos_emb_fourier_add:\n",
    "                cond_x=x+pos_fourier_xy\n",
    "                \n",
    "         \n",
    "            else:\n",
    "                cond_x= torch.cat( (cond_x,   pos_fourier_xy), 2)\n",
    "        ########################## END conditioning ####################################   \n",
    "        \n",
    "        \n",
    "        \n",
    "        if not self.predict_neighbors: \n",
    "            if self.predict_distance_matrix:\n",
    "                output= output [:,shift_input_depth:3+shift_input_depth+max_length,:]\n",
    "                #print (\"otuput \", output.shape)\n",
    "            elif encode_graphs:\n",
    "                output =output[:,shift_input_depth:shift_input_depth+3, :]\n",
    "    \n",
    "            else:\n",
    "                output =output[:,0:3, :]\n",
    "                 \n",
    "        if self.predict_neighbors: \n",
    "            \n",
    "            if encode_graphs:\n",
    "\n",
    "            \n",
    "                pos_1=shift_input_depth\n",
    "                pos_2=shift_input_depth+3\n",
    "                \n",
    "               # print (pos_1, pos_2)\n",
    "                \n",
    "                output_xyz =output[:,pos_1:pos_2, :]\n",
    "                output_neighbors =output[:,pos_2:pos_2+self.max_neighbors, :].long()\n",
    "               \n",
    "                output= pad_sequence (output_xyz, self.max_length)          \n",
    "\n",
    "                for i  in range (self.max_neighbors):\n",
    "                    #grab next neihhor tensor:\n",
    "                    x_neigh_l=output_neighbors[:,i,:] \n",
    "\n",
    "\n",
    "                    x_neigh_l = torch.unsqueeze(x_neigh_l, dim=-1)\n",
    "\n",
    "                    if self.neigh_emb_trainable:\n",
    "                        x_cc =  self.neigh_embs(x_neigh_l)\n",
    "                    else:\n",
    "                        with torch.no_grad():\n",
    "                            x_cc =  self.neigh_embs(x_neigh_l)\n",
    "\n",
    "    \n",
    "                    x_cc = torch.squeeze(x_cc, 2)\n",
    "                    x_cc=torch.permute(x_cc, (0,2,1)  )\n",
    "             \n",
    "                    if i==0:\n",
    "                        output= torch.cat( (output_xyz, x_cc  ), 1)\n",
    "\n",
    "                    else:    \n",
    "                        output= torch.cat( (output, x_cc ), 1)\n",
    "                ###########################################################        \n",
    "\n",
    "        pos_fourier_graph=self.p_enc_1d_graph( torch.ones (output.shape[0],\n",
    "                                                           self.pos_fourier_graph_dim,\n",
    "                                                           output.shape[2] ).to(device) ) \n",
    "        \n",
    "      \n",
    "        output=torch.cat( (output, pos_fourier_graph ), 1)\n",
    "        \n",
    "        output=torch.permute(output, (0,2,1)  )\n",
    "        \n",
    "        start_tokens = repeat(self.start_token, 'd -> b 1 d', b = output.shape[0])\n",
    "            \n",
    "        output = torch.cat((start_tokens, output), dim = 1)\n",
    "        \n",
    "        if return_loss:\n",
    "           \n",
    "            output, target = output[:, :-1,:], output[:, 1:,:self.logits_dim]\n",
    "    \n",
    "\n",
    "        if not exists(text_mask):\n",
    "            text_mask = torch.ones(cond_x.shape[:2], dtype = torch.bool).to(device)\n",
    "            \n",
    "        cond_x, text_mask = map(lambda t: t[:, :self.max_text_len], (cond_x, text_mask))\n",
    "\n",
    "        batch=output.shape[0]\n",
    "        if cond_drop_prob > 0:\n",
    "            keep_mask = prob_mask_like((batch,), 1 - cond_drop_prob, device = device)\n",
    "            text_mask = rearrange(keep_mask, 'b -> b 1') & text_mask\n",
    "\n",
    "       \n",
    "        x = self.to_dim(output)\n",
    "        x = self.init_norm(x)\n",
    "\n",
    "        for self_attn, cross_attn, ff in self.layers:\n",
    "            x = self_attn(x) + x\n",
    "            x = cross_attn(x, context = cond_x, context_mask = text_mask) + x\n",
    "            x = ff(x) + x\n",
    "\n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        logits = self.to_logits(x)\n",
    "        logits=torch.permute(logits, (0,2,1)  )\n",
    "\n",
    "        if not return_loss:\n",
    "            return logits\n",
    "        \n",
    "        if self.use_categorical_for_neighbors:\n",
    "\n",
    "          \n",
    "            target=torch.permute(target, (0,2,1)  )\n",
    "           \n",
    "            loss_xyz = F.mse_loss(\n",
    "               \n",
    "                logits[:,:3,:], target[:,:3,:]\n",
    "            )\n",
    "            \n",
    "            loss_neigh=0\n",
    "           \n",
    "            \n",
    "            for i in range ( self.max_neighbors ):\n",
    "                neighbor_logits_i=logits[:,\n",
    "                                       3+i*self.max_tokens:3+(i+1)*self.max_tokens, \n",
    "                                       :]\n",
    "                target_i = output_neighbors[:,i,:].long()\n",
    "                \n",
    "                rearr_logits_i=neighbor_logits_i\n",
    "                \n",
    "                loss_i=F.cross_entropy(\n",
    "                           rearr_logits_i,\n",
    "                            target_i,\n",
    "                          #  ignore_index = 0\n",
    "                        )\n",
    "\n",
    "                loss_neigh =loss_neigh+ loss_i\n",
    "                \n",
    "            loss=loss_xyz +loss_neigh \n",
    "            \n",
    "            return loss\n",
    "                \n",
    "\n",
    "        #OPTION 1: Use MSE for everything, and use embedding \n",
    "        if not self.use_categorical_for_neighbors:\n",
    "\n",
    "        \n",
    "            target=torch.permute(target, (0,2,1)  )\n",
    "          \n",
    "            loss = F.mse_loss(\n",
    "        \n",
    "                logits, target\n",
    "            )\n",
    "\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e948e92",
   "metadata": {},
   "source": [
    "### Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f212c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop (model,\n",
    "                train_loader,test_loader,\n",
    "                optimizer=None,\n",
    "                print_every=10,\n",
    "                epochs= 300,\n",
    "                start_ep=0,\n",
    "                start_step=0,\n",
    "                train_unet_number=1,\n",
    "                print_loss=1000,\n",
    "                plot_unscaled=False,\n",
    "                save_model=False,\n",
    "                cond_scales=[7.5], #list of cond scales  \n",
    "                num_samples=2,  \n",
    "                 enforce_symmetry=False,\n",
    "                save_loss_images=False,clamp=False,\n",
    "                corplot=False,show_neighbors=False,xyz_and_graph=True,\n",
    "               ):\n",
    "    \n",
    "    steps=start_step\n",
    "    start = time.time()\n",
    "    \n",
    "\n",
    "    loss_total=0\n",
    "    for e in range(1, epochs+1):\n",
    "            start = time.time()\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "          \n",
    "            train_epoch_loss = 0\n",
    "            model.train()\n",
    "            \n",
    "            for item  in train_loader:\n",
    "\n",
    "\n",
    "                X_train_batch= item[0].to(device)\n",
    "                y_train_batch=item[1].to(device)\n",
    "\n",
    "                X_train_batch=torch.permute(X_train_batch, (0,2,1)  )\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "                loss= model(\n",
    "                        sequences=y_train_batch,#conditioning\n",
    "                        output=X_train_batch,\n",
    "                        text_mask = None,\n",
    "                    \n",
    "                        return_loss = True,\n",
    "                    encode_graphs=True,\n",
    "                        \n",
    "                )\n",
    "                \n",
    "                loss.backward( )\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_total=loss_total+loss.item()\n",
    "\n",
    "                if steps % print_every == 0:\n",
    "                    print(\".\", end=\"\")\n",
    "\n",
    "                if steps>0:\n",
    "                    if steps % print_loss == 0:\n",
    "                        norm_loss=loss_total/print_loss\n",
    "                        print (f\"\\nTOTAL LOSS at epoch={e}, step={steps}: {norm_loss}\")\n",
    "\n",
    "                        loss_list.append (norm_loss)\n",
    "                        loss_total=0\n",
    "\n",
    "                        plt.plot (loss_list, label='Loss')\n",
    "                        plt.legend()\n",
    " \n",
    "                        if save_loss_images:\n",
    "                            outname = prefix+ f\"loss_{e}_{steps}.jpg\"\n",
    "                            plt.savefig(outname, dpi=200)\n",
    "                        plt.show()\n",
    "                        \n",
    "                        sample_loop (model,\n",
    "                                test_loader,\n",
    "                                cond_scales=cond_scales, #list of cond scales - each sampled...\n",
    "                                num_samples=num_samples, #how many samples produced every time tested.....\n",
    "                                clamp=clamp,corplot=corplot,\n",
    "                                save_img=save_loss_images,show_neighbors=show_neighbors,\n",
    "                                flag=steps,xyz_and_graph=xyz_and_graph,  enforce_symmetry=enforce_symmetry\n",
    "                                    )\n",
    "                        \n",
    "                        print (f\"\\n\\n-------------------\\nTime passed for {print_loss} epochs at {steps} = {(time.time()-start)/60} mins\\n-------------------\")\n",
    "                        start = time.time()\n",
    "                        if save_model:\n",
    "                            \n",
    "                            fname=f\"{prefix}statedict_save-model-epoch_{e}.pt\"\n",
    "                            torch.save(model.state_dict(), fname)\n",
    "                            print (f\"Model saved: \", fname)\n",
    "                \n",
    "                steps=steps+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05ba60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def sample_loop (model,\n",
    "                train_loader,\n",
    "                cond_scales=[7.5], #list of cond scales - each sampled...\n",
    "                num_samples=2, #how many samples produced every time tested.....\n",
    "              \n",
    "                 flag=0,clamp=False,\n",
    "                 corplot=False,\n",
    "                 save_img=False,\n",
    "                 show_neighbors=False,\n",
    "                xyz_and_graph=False,GED=False,\n",
    "                 filter_thres = 0.9,temperature=1.,\n",
    "                 enforce_symmetry = False, #if True: make distance matrix symmetric\n",
    "                 clamp_round_results=True,dist_matrix_threshold=0.25,\n",
    "                 \n",
    "               ):\n",
    "    steps=0\n",
    "    e=flag\n",
    "    for item  in train_loader:\n",
    "\n",
    "            X_train_batch= item[0]\n",
    "            y_train_batch=item[1].to(device)\n",
    "            \n",
    "            X_train_batch=torch.permute(X_train_batch, (0,2,1)  )\n",
    "\n",
    "            GT=y_train_batch.cpu().detach().unsqueeze(1) \n",
    "            \n",
    "            num_samples = min (num_samples,y_train_batch.shape[0] )\n",
    "            print (f\"Producing {num_samples} samples...\")\n",
    "\n",
    "            for iisample in range (len (cond_scales)):\n",
    "\n",
    "                result = GWebT.generate(        sequences=y_train_batch,#conditioning\n",
    "                        cond_scale = cond_scales[iisample],filter_thres = filter_thres,temperature=temperature,\n",
    "                                        use_argmax=False,\n",
    "                     ) # conditioning scale for classifier free guidance\n",
    "                 \n",
    "                if clamp_round_results:\n",
    "                    result[:, 3:3+max_length, :]=torch.clamp(result[:, 3:3+max_length, :], 0, 1) \n",
    "                \n",
    "                if enforce_symmetry:\n",
    "                    result[:, 3:3+max_length, :]=0.5*(result[:, 3:3+max_length, :]+\\\n",
    "                                                      torch.transpose (result[:, 3:3+max_length, :], 1, 2 ) )\n",
    "                if clamp_round_results:\n",
    "                    result[:, 3:3+max_length, :]=torch.clamp(result[:, 3:3+max_length, :], 0, 1) \n",
    "                \n",
    "                result[:, 3:3+max_length, :] [result[:, 3:3+max_length, :]< dist_matrix_threshold]=0\n",
    "                result[:, 3:3+max_length, :] [result[:, 3:3+max_length, :]>= dist_matrix_threshold]=1\n",
    "\n",
    "                result=result.cpu() \n",
    "\n",
    "                X_train_batch= pad_sequence (X_train_batch,  max_length).cpu()\n",
    "                if xyz_and_graph:\n",
    "                    y_data_coll_pred=[]\n",
    "                    y_data_coll_GT=[]                \n",
    "                for samples in range  (num_samples):\n",
    "                    \n",
    "                   \n",
    "                    GTroundL = torch.nonzero(X_train_batch[samples, 4:4+max_length, :]).flatten().max()+1\n",
    "                    resroundL = torch.nonzero(result[samples, 3:3+max_length, :]).flatten().max()+1\n",
    "                    \n",
    "                    fig, ax = plt.subplots(1, 2, figsize=(10, 6) , subplot_kw=dict(projection='3d'))\n",
    "                    \n",
    "                    xs=X_train_batch[samples, 1, :GTroundL]\n",
    "                    ys=X_train_batch[samples, 2, :GTroundL]\n",
    "                    zs=X_train_batch[samples, 3, :GTroundL]\n",
    "                    m=6\n",
    "                    ax[0].scatter(xs, ys, zs, c='red', s=m, marker=\"o\")\n",
    "\n",
    "                    ax[0].set_xlabel('X')\n",
    "                    ax[0].set_ylabel('Y')\n",
    "                    ax[0].set_zlabel('Z')\n",
    "                    ax[0].set_title('GT')\n",
    "                    ax[0].set_xlim(-1,1)\n",
    "                    ax[0].set_ylim(-1,1)\n",
    "                    ax[0].set_zlim(-1,1)\n",
    "\n",
    "                    xs=result[samples, 0, :resroundL]\n",
    "                    ys=result[samples, 1, :resroundL]\n",
    "                    zs=result[samples, 2, :resroundL]\n",
    "                    m=6\n",
    "                    ax[1].scatter(xs, ys, zs, c='red', s=m, marker=\"o\")\n",
    "\n",
    "                    ax[1].set_xlabel('X')\n",
    "                    ax[1].set_ylabel('Y')\n",
    "                    ax[1].set_zlabel('Z')\n",
    "                    ax[1].set_xlim(-1,1)\n",
    "                    ax[1].set_ylim(-1,1)\n",
    "                    ax[1].set_zlim(-1,1)                    \n",
    "                    \n",
    "                    ax[1].set_title('Prediction')\n",
    "                    if save_img:\n",
    "                            outname = prefix+ f\"img_{flag}.png\"\n",
    "                            plt.savefig(outname, dpi=300)\n",
    "                    \n",
    "                    plt.show()\n",
    "                    \n",
    "                    fig, ax = plt.subplots(1, 2, figsize=(10, 6)  )\n",
    "                    \n",
    "                     \n",
    "                    xs=X_train_batch[samples, 1, :GTroundL]\n",
    "                    ys=X_train_batch[samples, 2, :GTroundL]\n",
    "                    zs=X_train_batch[samples, 3, :GTroundL]\n",
    "                    m=2\n",
    "                    ax[0].plot(xs, ys , 'bo', markersize=m, label='Y over X')\n",
    "                    ax[0].plot(xs, zs,'ro', markersize=m, label='Z over X')\n",
    "\n",
    "                    ax[0].set_xlabel('X')\n",
    "                    ax[0].set_ylabel('Y/Z')\n",
    "                 \n",
    "                    ax[0].set_title('GT')\n",
    "                    ax[0].axis('square')\n",
    "                    ax[0].set_xlim(-1,1)\n",
    "                    ax[0].set_ylim(-1,1)\n",
    "                    ax[0].legend()\n",
    "                    \n",
    "                  \n",
    "                    xs=result[samples, 0, :resroundL]\n",
    "                    ys=result[samples, 1, :resroundL]\n",
    "                    zs=result[samples, 2, :resroundL]\n",
    "                     \n",
    "                    ax[1].plot(xs, ys ,'bo', markersize=m, label='Y over X')\n",
    "                    ax[1].plot(xs, zs,'ro', markersize=m, label='Z over X')\n",
    "\n",
    "                    ax[1].set_xlabel('X')\n",
    "                    ax[1].set_ylabel('Y/Z')\n",
    "                    #ax[1].set_zlabel('Z')\n",
    "                    ax[1].axis('square')\n",
    "                    ax[1].set_xlim(-1,1)\n",
    "                    ax[1].set_ylim(-1,1)\n",
    "                    #ax[1].set_zlim(-1,1)                    \n",
    "                    ax[1].legend()\n",
    "                    \n",
    "                    \n",
    "                    ax[1].set_title('Prediction')\n",
    "                    if save_img:\n",
    "                            outname = prefix+ f\"img_proj_{flag}.png\"\n",
    "                            plt.savefig(outname, dpi=300)\n",
    "                    \n",
    "                    plt.show()\n",
    "                    \n",
    "                    \n",
    "                    if show_neighbors:\n",
    "                        fig, ax = plt.subplots(1, 2, figsize=(10, 6)  )\n",
    "                    \n",
    "                        ax[1].imshow (result [samples, 3:3+max(GTroundL,resroundL), :max(GTroundL,resroundL)])\n",
    "                        ax[0].imshow (X_train_batch [samples, 4:4+max(GTroundL,resroundL), :max(GTroundL,resroundL)])\n",
    "                        ax[1].set_title('Prediction')\n",
    "                        ax[0].set_title('GT')\n",
    "                     \n",
    "                        plt.show()\n",
    "                        \n",
    "                        fig, ax = plt.subplots(1, 2, figsize=(10, 6)  )\n",
    "                    \n",
    "                        ax[1].imshow (result [samples, 3:3+max_length, :])\n",
    "                        ax[0].imshow (X_train_batch [samples, 4:4+max_length, :])\n",
    "                        ax[1].set_title('Prediction')\n",
    "                        ax[0].set_title('GT')                        \n",
    "                        #ax[0].grid(False)\n",
    "                       # ax[1].grid(False)\n",
    "                        plt.show()\n",
    "                        \n",
    "                    if xyz_and_graph:\n",
    "                        G_res, data_res, y_data_pred =construct_xyz_and_graph (result[samples,:3+resroundL,:resroundL].squeeze(),\n",
    "                                                 fname_root=f'{prefix}graph_xyz_{samples}_{flag}_{steps}',\n",
    "                                                                label='Prediction', #limits=[X_min*1.2, X_max*1.2],\n",
    "                                                                dist_matrix=True)\n",
    "                        G_GT, data_GT, y_data_GT=construct_xyz_and_graph (X_train_batch[samples, 1:4+GTroundL, :GTroundL].squeeze(),\n",
    "                                                 fname_root=f'{prefix}graph_GT_xyz_{samples}_{flag}_{steps}',\n",
    "                                                              label='GT',dist_matrix=True)\n",
    "                        \n",
    "                        \n",
    "\n",
    "                        plt.plot ( y_data_GT, y_data_pred, '.',label='Graph properties (GT vs predicted)',markersize=12 )\n",
    "                        plt.legend()\n",
    "                        plt.xlabel ('GT')\n",
    "                        plt.ylabel ('Predicted')\n",
    "                        min_v,max_v=min (min(y_data_GT), min (y_data_pred)),max (max(y_data_GT), max (y_data_pred))\n",
    "                        plt.plot([min_v, max_v], [min_v, max_v], ls=\"--\", c=\".3\")\n",
    "                        plt.axis ('square')\n",
    "                        plt.show()\n",
    "                        \n",
    "                        #print (y_max, y_min,GT.shape[2])\n",
    "                        for i in range (len(y_min)):\n",
    "                            y_data_pred[i]=scale_data(y_data_pred[i], y_max[i],y_min[i]) \n",
    "                            y_data_GT[i]=scale_data(y_data_GT[i], y_max[i],y_min[i]) \n",
    "                            \n",
    "                        plt.plot ( y_data_GT, y_data_pred, '.',label='Graph properties (GT vs predicted)',markersize=12 )\n",
    "                        plt.legend()\n",
    "                        plt.xlabel ('GT')\n",
    "                        plt.ylabel ('Predicted')\n",
    "                        plt.plot([-1, 1], [-1, 1], ls=\"--\", c=\".3\")\n",
    "                        plt.axis ('square')\n",
    "                        plt.show()\n",
    "                        \n",
    "                        y_data_coll_pred.append (y_data_pred)\n",
    "                        y_data_coll_GT.append (y_data_GT)#.cpu().numpy())\n",
    "                        \n",
    "                        if GED:\n",
    "                            GED=nx.graph_edit_distance (G_res, G_GT)\n",
    "                            print (\"Graph edit distance=\", GED)\n",
    "                        print (f\"\")\n",
    "                        \n",
    "                    if corplot:\n",
    "                        plt.plot (X_train_batch[samples, 1:4, :].flatten().detach().cpu(), \n",
    "                                  result[samples, 0:3, :].flatten() , '.',label='all',markersize=6 )\n",
    "                        plt.plot (X_train_batch[samples, 1, :].flatten().detach().cpu(), \n",
    "                                  result[samples, 0, :].flatten() , '.',label='x',markersize=2 )\n",
    "                        plt.plot (X_train_batch[samples, 2, :].flatten().detach().cpu(), \n",
    "                                  result[samples, 1, :].flatten() , '.',label='y',markersize=2 )\n",
    "                        plt.plot (X_train_batch[samples, 3, :].flatten().detach().cpu(), \n",
    "                                  result[samples, 2, :].flatten() , '.',label='z',markersize=2 )\n",
    "                        \n",
    "                        plt.legend()\n",
    "                        \n",
    "                        plt.plot([-1, 1], [-1, 1], ls=\"--\", c=\".3\")\n",
    "                        plt.axis ('square')\n",
    "                        plt.show()\n",
    "                        \n",
    "                y_data_coll_pred=np.array(y_data_coll_pred).flatten()\n",
    "                y_data_coll_GT=np.array(y_data_coll_GT).flatten()        \n",
    "                \n",
    "              \n",
    "                R2=r2_score(y_data_coll_GT, y_data_coll_pred)\n",
    "                print (\"OVERALL R2: \", R2)\n",
    "                plt.plot ( y_data_coll_GT, y_data_coll_pred, '.', label='Graph properties (GT vs predicted)',markersize=3 )\n",
    "                plt.legend()\n",
    "                plt.xlabel ('GT')\n",
    "                plt.ylabel ('Predicted')\n",
    "                plt.plot([-1, 1], [-1, 1], ls=\"--\", c=\".3\")\n",
    "                plt.axis ('square')\n",
    "                plt.title (\"Correlation prediction vs. GT\")\n",
    "                plt.show()                        \n",
    "                        \n",
    "            steps=steps+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a65e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_cond (model,\n",
    "              \n",
    "                cond_scales=[7.5], #list of cond scales - each sampled...\n",
    "               # num_samples=2, #how many samples produced every time tested.....\n",
    "                \n",
    "                 flag=0,clamp=False,\n",
    "                 corplot=False,\n",
    "                 save_img=False,\n",
    "                 show_neighbors=False,\n",
    "                xyz_and_graph=False,GED=False,\n",
    "                cond=[1., .5, 1.],\n",
    "                  enforce_symmetry = True, #if True: make distance matrix symmetric\n",
    "                          dist_matrix_threshold=0.25,\n",
    "               ):\n",
    "    steps=0\n",
    "    e=flag\n",
    "\n",
    "    y_train_batch=torch.Tensor (cond).to(device)\n",
    "    y_train_batch=y_train_batch.unsqueeze(0) \n",
    "  \n",
    "    for iisample in range (len (cond_scales)):\n",
    "        \n",
    "        samples=0\n",
    "        \n",
    "        result = GWebT.generate(        sequences=y_train_batch,#conditioning\n",
    "                cond_scale = cond_scales[iisample],\n",
    "                                use_argmax=False,\n",
    "             ) \n",
    "        result[:, 3:3+max_length, :]=torch.clamp(result[:, 3:3+max_length, :], 0, 1) \n",
    "\n",
    "        if enforce_symmetry:\n",
    "            result[:, 3:3+max_length, :]=0.5*(result[:, 3:3+max_length, :]+\\\n",
    "                                              torch.transpose (result[:, 3:3+max_length, :], 1, 2 ) )\n",
    "            result[:, 3:3+max_length, :]=torch.clamp(result[:, 3:3+max_length, :], 0, 1) \n",
    "\n",
    "        result[:, 3:3+max_length, :] [result[:, 3:3+max_length, :]< dist_matrix_threshold]=0\n",
    "        result[:, 3:3+max_length, :] [result[:, 3:3+max_length, :]>= dist_matrix_threshold]=1\n",
    "\n",
    "        result=result.cpu() \n",
    "\n",
    "        resroundL = torch.nonzero(result[samples, 3:3+max_length, :]).flatten().max()\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5, 6) , subplot_kw=dict(projection='3d'))\n",
    "\n",
    "        ax=[ax]\n",
    "\n",
    "        xs=result[samples, 0, :resroundL]\n",
    "        ys=result[samples, 1, :resroundL]\n",
    "        zs=result[samples, 2, :resroundL]\n",
    "        m=6\n",
    "        ax[0].scatter(xs, ys, zs, c='red', s=m, marker=\"o\")\n",
    "\n",
    "        ax[0].set_xlabel('X')\n",
    "        ax[0].set_ylabel('Y')\n",
    "        ax[0].set_zlabel('Z')\n",
    "        ax[0].set_xlim(-1,1)\n",
    "        ax[0].set_ylim(-1,1)\n",
    "        ax[0].set_zlim(-1,1)                    \n",
    "\n",
    "        ax[0].set_title('Prediction')\n",
    "        if save_img:\n",
    "                outname = prefix+ f\"img_{flag}.png\"\n",
    "                plt.savefig(outname, dpi=300)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5, 6)  )\n",
    "\n",
    "        ax=[ax]\n",
    "\n",
    "        xs=result[samples, 0, :resroundL]\n",
    "        ys=result[samples, 1, :resroundL]\n",
    "        zs=result[samples, 2, :resroundL]\n",
    "\n",
    "        ax[0].plot(xs, ys ,'bo', markersize=m, label='Y over X')\n",
    "        ax[0].plot(xs, zs,'ro', markersize=m, label='Z over X')\n",
    "\n",
    "        ax[0].set_xlabel('X')\n",
    "        ax[0].set_ylabel('Y/Z')\n",
    "        #ax[1].set_zlabel('Z')\n",
    "        ax[0].axis('square')\n",
    "        ax[0].set_xlim(-1,1)\n",
    "        ax[0].set_ylim(-1,1)\n",
    "        #ax[1].set_zlim(-1,1)                    \n",
    "        ax[0].legend()\n",
    "\n",
    "\n",
    "        ax[0].set_title('Prediction')\n",
    "        if save_img:\n",
    "                outname = prefix+ f\"img_proj_{flag}.png\"\n",
    "                plt.savefig(outname, dpi=300)\n",
    "\n",
    "        plt.show()\n",
    "                    \n",
    "        if show_neighbors:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5, 6)  )\n",
    "            ax=[ax]\n",
    "            ax[0].imshow (result [samples, 3:3+max(resroundL,resroundL), :max(resroundL,resroundL)])\n",
    "            #ax[0].imshow (X_train_batch [samples, 4:4+max(GTroundL,resroundL), :max(GTroundL,resroundL)])\n",
    "            ax[0].set_title('Prediction')\n",
    "            #ax[0].grid(False)\n",
    "            #ax[0].set_title('GT')\n",
    "            plt.show()\n",
    "\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5, 6)  )\n",
    "            ax=[ax]\n",
    "            ax[0].imshow (result [samples, 3:3+max_length, :])\n",
    "            #ax[0].imshow (X_train_batch [samples, 4:4+max_length, :])\n",
    "            ax[0].set_title('Prediction')\n",
    "            #ax[0].grid(False)\n",
    "            #ax[0].set_title('GT')                        \n",
    "            plt.show()\n",
    "\n",
    "        if xyz_and_graph:\n",
    "            for i in range (len(y_min)):\n",
    "                y_train_batch[0,i]=unscale_data(y_train_batch[0,i], y_max[i],y_min[i]) \n",
    "                \n",
    "            G_res, data_res, y_data_pred =construct_xyz_and_graph (result[0,:3+resroundL,:resroundL].squeeze(),\n",
    "                                     fname_root=f'{prefix}graph_xyz_{flag}',\n",
    "                                                    label='Prediction', #limits=[X_min*1.2, X_max*1.2],\n",
    "                                                    dist_matrix=True,\n",
    "                                                 GT_y=y_train_batch[0,:].cpu().numpy())\n",
    "              \n",
    "    steps=steps+1\n",
    "    if xyz_and_graph:\n",
    "        return result[samples, :resroundL+3, :resroundL].squeeze().permute(1,0), G_res, data_res,y_data\n",
    "    else:\n",
    "        return result[samples, :resroundL+3, :resroundL].squeeze().permute (1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af9399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    " \n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "def add_edge_to_graph(G, e1, e2, w):\n",
    "    G.add_edge(e1, e2, weight=w,\n",
    "              clamp_neighbors=True)\n",
    "def get_properties(item):\n",
    "    #print (item.edge_index, item.num_edges)\n",
    "    #print (item)\n",
    "    length=0\n",
    "    dx,dy,dz=0,0,0\n",
    "    \n",
    "    for jj in range (item.num_edges):\n",
    "        dx_=item.pos[item.edge_index[0,jj],0]-item.pos[item.edge_index[1,jj],0]\n",
    "        dy_=item.pos[item.edge_index[0,jj],1]-item.pos[item.edge_index[1,jj],1]\n",
    "        dz_=item.pos[item.edge_index[0,jj],2]-item.pos[item.edge_index[1,jj],2]\n",
    "        \n",
    "        dx=dx+dx_\n",
    "        dy=dy+dy_\n",
    "        dz=dz+dz_\n",
    "        \n",
    "        length=length + (dx_**2+dy_**2+dz_**2)**0.5\n",
    "        \n",
    "    avg_length = length /item.num_edges     \n",
    "    dx, dy, dz = dx/item.num_edges, dy/item.num_edges, dz/item.num_edges\n",
    "        \n",
    "    num_nodes=item.num_nodes\n",
    "    num_edges=item.num_edges\n",
    "    node_degree=item.num_edges / item.num_nodes\n",
    "    \n",
    "     \n",
    "    return avg_length.numpy(),dx.numpy(), dy.numpy(), dz.numpy(), num_nodes , num_edges, node_degree\n",
    "\n",
    "def construct_xyz_and_graph (result, fname_root='output',\n",
    "                             clamp_neighbors=True,label='Generated',\n",
    "                             limits=None,#axis limits for plot, \n",
    "                             GT_y=None,\n",
    "                             dist_matrix=False,\n",
    "                             \n",
    "                            ):\n",
    "    print (\"##############################################################################\")\n",
    "    print (\"Shape of data provided \", result.shape) \n",
    "    print (f\"Root file: {fname_root}\")\n",
    "    print (\"##############################################################################\")\n",
    "        \n",
    "    result[ :3, :]=unscale_data(result[:3,: ], X_max.numpy(),X_min.numpy())\n",
    "\n",
    "    xs=result[ 0, :]\n",
    "    ys=result[ 1, :]\n",
    "    zs=result[ 2, :]\n",
    "    \n",
    "    with open(fname_root+'.xyz', 'w') as f:\n",
    "        f.write('#ID x y z \\n')\n",
    "        for i in range (result.shape[1]):\n",
    "            f.write(f'{i+1} {xs[i]} {ys[i]} {zs[i]} \\n')\n",
    "    \n",
    "    node_list=[]\n",
    "    neighbor_list=[]\n",
    "    point_list=[]\n",
    "    \n",
    "    \n",
    "    #now prepare graph\n",
    "    for i in range (result.shape[1]):\n",
    "        node_list.append ( [xs[i], ys[i], zs[i] ])\n",
    "        point_list.append ( (xs[i], ys[i], zs[i]  ))\n",
    "        \n",
    "        if not dist_matrix:\n",
    "            #neighbors are stored in result [4,5,..., 9]\n",
    "            for j in range (max_neighbors):\n",
    "                #neigh_j=i-int (result[ 3+j, i] )   +1\n",
    "                neigh_j=result[ 3+j, i] \n",
    "                #print (neigh_j)\n",
    "                if neigh_j !=0: #zeros are padded values...\n",
    "                    #f neigh_j !=0:\n",
    "                    neighn=  neigh_j-1 #neigh_j is 1+node number (since it encodes 0s....as padding)\n",
    "\n",
    "                    if clamp_neighbors:\n",
    "                        neighn=max( 0, min (neighn, result.shape[1]-1) )\n",
    "\n",
    "\n",
    "                    neighbor_list.append ([i,neighn] )  #val=node1- node2 +1  --> node2= node1- val  +1\n",
    "                    \n",
    "        if dist_matrix:\n",
    "            for j in range (result.shape[1]):\n",
    "                #neigh_j=i-int (result[ 3+j, i] )   +1\n",
    "                neigh_j=result[ 3+j, i] \n",
    "                #print (neigh_j)\n",
    "                if neigh_j >0.5: #zeros are padded values... a value of >0.5 means a neighbor is found\n",
    "                    #f neigh_j !=0:\n",
    "                    neighn=  j\n",
    "\n",
    "                    neighbor_list.append ([i,neighn] )  #val=node1- node2 +1  --> node2= node1- val  +1\n",
    "            \n",
    "\n",
    "    with open(fname_root+'.dump', 'w') as f:\n",
    "        f.write(f'\\n{result.shape[1]} atoms\\n{len (neighbor_list)} bonds  \\n\\n1 atom types\\n1 bond types\\n\\n')\n",
    "        f.write(f'0 500 xlo xhi \\n0 500 ylo yhi \\n0 500 zlo zhi \\n\\n')\n",
    "        f.write(f'Masses \\n\\n1 100.00  \\n\\n')\n",
    "        f.write(f'Atoms  \\n\\n')\n",
    "\n",
    "\n",
    "        for i in range (result.shape[1]):\n",
    "            f.write(f'{i+1} 1 1 {xs[i]} {ys[i]} {zs[i]} \\n')\n",
    "        f.write(f'\\nBonds  \\n\\n')\n",
    "\n",
    "        for i in range (len (neighbor_list)):\n",
    "            f.write(f'{i+1} 1 {neighbor_list[i][0]} { max( 1, min (neighbor_list[i][1], result.shape[1]) )}   \\n')\n",
    "        f.write(f'\\n\\n')\n",
    "    \n",
    "\n",
    "    #rint (node_list)\n",
    "    #print (neighbor_list)\n",
    "    \n",
    "    neighbor_list=torch.Tensor (neighbor_list).long()\n",
    "    print (\"neighborlist shape: \", neighbor_list.shape)\n",
    "    #print (neighbor_list)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    m=24\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(xs, ys, zs,c='red', s=m, marker=\"o\")\n",
    "    ax.set_proj_type('ortho')\n",
    "    ax.set_title (label)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    \n",
    "    print (\"STATS of neighbor list: max \", neighbor_list.max(), \"min \",  neighbor_list.min(), \"shape \", neighbor_list.shape)\n",
    "    \n",
    "    \n",
    "    for i in range (len (neighbor_list)):\n",
    "            \n",
    "            N1=neighbor_list[i][0] # because N1 and N2 refers to array indices, not note numbers\n",
    "            \n",
    "            N2=max( 0, min (neighbor_list[i][1], result.shape[1]-1) ) \n",
    "            #print (N1, N2)\n",
    "            ax.plot3D ([xs[N1], xs[N2]], [ys[N1], ys[N2]] , [zs[N1], zs[N2]], 'k-', linewidth=1, )\n",
    "           \n",
    "            \n",
    "    if limits != None:\n",
    "        ax.set_xlim(limits[0],limits[1])\n",
    "        ax.set_ylim(limits[0],limits[1])\n",
    "        ax.set_zlim(limits[0],limits[1])    \n",
    "        \n",
    "    plt.savefig (fname_root+'.png', dpi=400)\n",
    "    plt.savefig (fname_root+'.svg', dpi=400)\n",
    "    plt.show()\n",
    "    \n",
    "    print (\"Neighborlist shape COO^T format: \", neighbor_list.shape)\n",
    "    x = torch.tensor(node_list, dtype=torch.float)  #Node feature matrix with shape [num_nodes, num_node_features]\n",
    "    edge_index =neighbor_list.permute(1,0)  #Graph connectivity in COO format with shape [2, num_edges] and type torch.long\n",
    "    y = None #torch.tensor(graph_label, dtype=torch.float)  #Target to train against (may have arbitrary shape), e.g., node-level targets of shape [num_nodes, *] or graph-level targets of shape [1, *]\n",
    "    data = Data(x=x,pos=x, edge_index=edge_index, y=y)\n",
    "    \n",
    "    torch.save (data, fname_root+'.pt')\n",
    "    \n",
    "    print(f'Number of nodes: {data.num_nodes}')\n",
    "    print(f'Number of edges: {data.num_edges}')\n",
    "    print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "    G = to_networkx(data, to_undirected=False)\n",
    "    \n",
    "   # print(f\"radius: {nx.radius(G)} center: {nx.center(G)} density: {nx.density(G)}\")\n",
    "    \n",
    "    #nx.draw(G, with_labels=False,  )\n",
    "    print (\"##############################################################################\")\n",
    "    \n",
    "    \n",
    "    #Now calculate graph properties\n",
    "    \n",
    "    avg_length,dx, dy, dx, num_nodes , num_edges, node_degree=get_properties(data)\n",
    "    \n",
    "    y_data=np.array([avg_length,dx, dy, dx, num_nodes , num_edges, node_degree])\n",
    "    \n",
    "    print (f\"Graph properties measured: {labels_y_txt}\\n\",y_data)\n",
    "    if exists (GT_y):\n",
    "        print (f\"Graph properties GT: {labels_y_txt}\\n\", GT_y)\n",
    "        \n",
    "        plt.plot ( y_data, GT_y, '.',label='Graph properties (GT vs predicted)',markersize=12 )\n",
    "        plt.legend()\n",
    "        plt.xlabel ('GT')\n",
    "        plt.ylabel ('Predicted')\n",
    "        min_v,max_v=min (min(y_data), min (GT_y)),max (max(y_data), max (GT_y))\n",
    "        plt.plot([min_v, max_v], [min_v, max_v], ls=\"--\", c=\".3\")\n",
    "        plt.axis ('square')\n",
    "        plt.show()\n",
    "    return G,data, y_data\n",
    "    #visualize_graph(G, color=data.y)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce70896",
   "metadata": {},
   "source": [
    "### Set up model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea4f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e6c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11dd76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix='./Transformer_Model/'\n",
    "if not os.path.exists(prefix):\n",
    "        os.mkdir (prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865def02",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_neighbors, y_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c07fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim_neighbor=32\n",
    "\n",
    "GWebT = GraphWebTransformer(\n",
    "        dim=512,\n",
    "        depth=12,\n",
    "        dim_head = 64,\n",
    "        heads = 16,\n",
    "        dropout = 0.,\n",
    "        ff_mult = 4,\n",
    "        max_length=max_length,\n",
    "        neigh_emb_trainable=False,\n",
    "        max_norm=1.,#embedding ayer mnormed\n",
    "        pos_emb_fourier=True,\n",
    "        pos_emb_fourier_add=False,\n",
    "        text_embed_dim = 64,\n",
    "        embed_dim_position=64,\n",
    "        embed_dim_neighbor=embed_dim_neighbor,\n",
    "        predict_neighbors=True,#False,#whether or not to predict neighbors..\n",
    "        pos_fourier_graph_dim=67,#fourier pos encoding of entire graph\n",
    "        use_categorical_for_neighbors = False,\n",
    "        predict_distance_matrix=True,\n",
    "        cond_drop_prob = 0.25,\n",
    "        max_text_len = y_data.shape[1],\n",
    ").cuda()\n",
    "params (GWebT)\n",
    " \n",
    "optimizer = optim.Adam(GWebT.parameters() , lr=0.0001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ba8cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loop (GWebT,\n",
    "            train_loader,test_loader,\n",
    "            optimizer=optimizer,\n",
    "            print_every=10,\n",
    "            epochs= 20,\n",
    "            start_ep=0,\n",
    "            start_step=0,\n",
    "            train_unet_number=1,\n",
    "            print_loss =  50* (len (train_loader)-1),\n",
    "            plot_unscaled=False, \n",
    "            save_model=True,\n",
    "            cond_scales=[1],\n",
    "            num_samples=4,\n",
    "            clamp=True,corplot=False,\n",
    "            save_loss_images=False,show_neighbors=True,xyz_and_graph=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4bfbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname =f'{prefix}statedict_save-model-epoch_772.pt'\n",
    "GWebT.load_state_dict(torch.load(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801294b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_loop (   GWebT,\n",
    "                test_loader,\n",
    "                cond_scales=[1,  ], #list of cond scales - each sampled...\n",
    "                num_samples=16, #how many samples produced every time tested.....\n",
    "                clamp=True, corplot=False,show_neighbors=True,\n",
    "                xyz_and_graph=True, clamp_round_results=True, enforce_symmetry=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31287cfd",
   "metadata": {},
   "source": [
    "### Generate hierarchical structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7589c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length (X1):\n",
    "    return torch.nonzero(X1[:,3:]).flatten().max()+1\n",
    "    \n",
    "def get_length_xyzCOO (result):\n",
    "    return torch.nonzero(result[3 ,: ])[-1]+1 #first neighbor matters...\n",
    "    \n",
    "def get_xyz_and_dist_matrix_fromxyzCOO (X_data_cl, clamp_neighbors=False ,\n",
    "                            visualize=False, max_length=None):\n",
    "\n",
    "    if not exists (max_length):\n",
    "        max_length=get_length_xyzCOO (X_data_cl)\n",
    "    \n",
    "    X_data_cl=X_data_cl.permute (1,0)#bring to [max_length, xyz+max_neighbors]\n",
    "    print (X_data_cl.shape)\n",
    "        \n",
    "    max_neighbors=X_data_cl.shape[1]-3 \n",
    "    print (\"Max neighbors: \", max_neighbors, \"Length: \", max_length)\n",
    "    dist_matrix=torch.zeros (max_length, max_length)#.to(device)\n",
    "    \n",
    "    for i in range (max_length):\n",
    "\n",
    "        for j in range (max_neighbors):\n",
    "            #neigh_j=i-int (result[ 3+j, i] )   +1\n",
    "            neigh_j= X_data_cl[ i,3+j] \n",
    "\n",
    "            if neigh_j !=0: #zeros are padded values...\n",
    "\n",
    "                neighn=  neigh_j.long()\n",
    "\n",
    "                if clamp_neighbors:\n",
    "                    neighn=max( 1, min (neighn, max_length) )\n",
    "                    \n",
    "                \n",
    "\n",
    "                #print (dist_matrix.shape, j, neighn)\n",
    "                #dist_matrix[neighn-1, j] = 1\n",
    "                \n",
    "                \n",
    "                dist_matrix[i, neighn-1] = 1\n",
    "                dist_matrix[neighn-1, i] = 1\n",
    "\n",
    "    print (dist_matrix.shape,X_data_cl[:max_length, :3].shape )\n",
    "    output=  torch.cat( (X_data_cl[:max_length, :3],   dist_matrix), 1)\n",
    "    \n",
    "    print (\"Shape of new matrix (length, x,y,z+length+): \", output.shape)\n",
    "    \n",
    "        \n",
    "    if visualize:\n",
    "        \n",
    "        plt.imshow (output[:, 3:3+max_length])\n",
    "        plt.show()\n",
    "    return output\n",
    "    \n",
    "def shift (X2, dx, dy, dz):\n",
    "    X2[:, 0] =X2[:, 0] + dx\n",
    "    X2[:, 1] =X2[:, 1] + dy\n",
    "    X2[:, 2] =X2[:, 2] + dz\n",
    "    return X2\n",
    "    \n",
    "def stack_and_extend (X1, X2, stack_node, dx,dy,dz, \n",
    "                     fname_root='file_name',\n",
    "                      visualize=False,\n",
    "                      make_graph = False,\n",
    "                      avg_pos_in_overlap=False,\n",
    "                      \n",
    "                     ): #format: (dist matrix x distmatrix+xyz)\n",
    "    #stacks two  graphs and overlaps them\n",
    "    #stacknode determines where in X1 is second one added\n",
    "    \n",
    "    S1=get_length(X1) #X1.shape[0]\n",
    "    S2=get_length(X2) #X2.shape[0]\n",
    "    \n",
    "    S_new=stack_node+S2\n",
    "\n",
    "    dist_matrix=torch.zeros (S_new, S_new+3)#.to(device)\n",
    "    \n",
    "\n",
    "    X2[:, 0] =X2[:, 0] + dx\n",
    "    X2[:, 1] =X2[:, 1] + dy\n",
    "    X2[:, 2] =X2[:, 2] + dz\n",
    "    \n",
    "    dist_matrix[:S1, 3:3+S1]= X1 [:S1, 3:3+S1]\n",
    "    dist_matrix[stack_node:stack_node+S2, 3+stack_node:3+stack_node+S2]= X2 [:S2, 3:3+S2]\n",
    "    \n",
    "    #now average positions\n",
    "    \n",
    "    dist_matrix[:S1, :3]= X1[:, :3]\n",
    "    if avg_pos_in_overlap:\n",
    "        dist_matrix[stack_node:stack_node+S2, :3]= dist_matrix[stack_node:stack_node+S2, :3]+X2[:, :3]\n",
    "    else:\n",
    "        dist_matrix[stack_node:stack_node+S2, :3]=  X2[:, :3]\n",
    "   \n",
    "    #dist_matrix[stack_node:stack_node+S2, :3]= dist_matrix[stack_node:stack_node+S2, :3]/2.\n",
    "    if avg_pos_in_overlap: \n",
    "        dist_matrix[stack_node:S1, :3]= dist_matrix[stack_node:S1, :3]/2.\n",
    "    \n",
    "\n",
    "    #plt.plot (dist_matrix[:, 0])\n",
    "    #plt.plot (dist_matrix[:, 1])\n",
    "    #plt.plot (dist_matrix[:, 2])\n",
    "    \n",
    "    #plt.show()\n",
    "    if visualize:\n",
    "        \n",
    "        plt.imshow (dist_matrix[:S_new, 3:3+S_new])\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(X1[:,:3], aspect=.1)\n",
    "        plt.show()\n",
    "        plt.imshow(X2[:,:3], aspect=.1)\n",
    "        plt.show()\n",
    "        plt.imshow(dist_matrix[:,:3], aspect=.1)\n",
    "        plt.show()\n",
    "        \n",
    "    if make_graph:\n",
    "        G_res, data_respr, y_data_pred =construct_xyz_and_graph (dist_matrix.permute(1,0),\n",
    "                                     fname_root=fname_root,\n",
    "                                                    label='Stacked and extended', #limits=[X_min*1.2, X_max*1.2],\n",
    "                                                    dist_matrix=True,\n",
    "                                                  )\n",
    "    \n",
    "    return dist_matrix \n",
    "    \n",
    "\n",
    "    \n",
    "def make_spiral (X1, radius, \n",
    "                 slope_z, delta_angle, steps,  \n",
    "                stagger_fraction = 0.8,\n",
    "                fname_root='fname',\n",
    "                 visualize=True,visualize_all=False,\n",
    "                 shuffle=False,#shuflle graph\n",
    "                 \n",
    "                 avg_pos_in_overlap=False,\n",
    "                 \n",
    "                 generate_new_every_iteration=False,\n",
    "                 cond_vector_list=None,\n",
    "                 length_cond_vector=7,\n",
    "                 is_COO=False, #whether model predicts COO (sparse) or not\n",
    "                )   :\n",
    "\n",
    "    S1=get_length(X1)\n",
    "    delta_stagg=S1*stagger_fraction\n",
    "    \n",
    "    spiral = torch.clone (X1)\n",
    "    \n",
    "    i=-1\n",
    "    dx= radius * math.cos ((i+1)*delta_angle)\n",
    "    dy= radius * math.sin ((i+1)*delta_angle)\n",
    "    dz= slope_z *(i+1)\n",
    "\n",
    "    spiral = shift (spiral, dx, dy, dz)\n",
    "    for i in tqdm (range (steps)):\n",
    "        \n",
    "        #keep it in there in case i want to generate new graphs every time....\n",
    "       # S1=get_length(spiral)\n",
    "    \n",
    "        if generate_new_every_iteration:\n",
    "            if exists (cond_vector_list):\n",
    "                #[-0.7255, -0.2038,  0.5942,  0.3315,  0.286,  0.1852,  0.522]\n",
    "                cond_v=cond_vector_list[i]\n",
    "            else:\n",
    "                cond_v=1.5*torch.rand (length_cond_vector)-0.75\n",
    "            result, G_res, data_res,y_data= generate_sample_cond (GWebT,\n",
    "                cond=cond_v,#[-.5, 0.7, 0.6, 0.2, 0.3, 0.4, -0.9],\n",
    "                cond_scales=[1.,  ], #list of cond scales - each sampled...\n",
    "                flag=9992,\n",
    "              clamp=True, corplot=True,show_neighbors=True,\n",
    "            xyz_and_graph=True)\n",
    "            \n",
    "            \n",
    "            if is_COO:\n",
    "                X1=get_xyz_and_dist_matrix_fromxyzCOO (result, clamp_neighbors=True ,\n",
    "                                            visualize=False)#convert xyz-COO coding to xyz-distance matrix\n",
    "            else:\n",
    "                X1=result\n",
    "            S1=get_length(X1)\n",
    "            delta_stagg=S1*stagger_fraction\n",
    "    \n",
    "\n",
    "\n",
    "        if shuffle:\n",
    "            \n",
    "            if visualize_all:\n",
    "                plt.imshow (X1[:S1, 3:3+S1])\n",
    "                plt.show()               \n",
    "            ar=torch.range (0,S1-1).long()\n",
    "            ar2=torch.range (0,S1-1+3).long()\n",
    "            c=torch.randperm(S1)\n",
    "            c2=torch.cat( (torch.range (0,2), c+3)).long()\n",
    "            #print (X1.shape,\"S1\", S1, \"v \", ar, ar2, c, c2)\n",
    "            X1=torch.cat( ( X1[:,:3],  X1.clone () [ar][c,3:]), 1)\n",
    "            #print (X1.shape)\n",
    "            X1=X1[:,ar2][:,c2]\n",
    "            \n",
    "            if visualize_all:\n",
    "                plt.imshow (X1[:S1, 3:3+S1])\n",
    "                plt.show()     \n",
    "    \n",
    "       \n",
    "        stack_node=int (get_length(spiral)-delta_stagg )\n",
    "        \n",
    "        #print (\"stack node: \", stack_node, i)\n",
    "    \n",
    "        dx= radius * math.cos ((i+1)*delta_angle)\n",
    "        dy= radius * math.sin ((i+1)*delta_angle)\n",
    "        dz= slope_z *(i+1)\n",
    "        \n",
    "        #print (dx, dy, dz)\n",
    "        spiral=stack_and_extend (spiral.clone(), X1.clone(), stack_node, dx,dy,dz, \n",
    "                      visualize=False,\n",
    "                      make_graph = False,avg_pos_in_overlap=avg_pos_in_overlap,\n",
    "                     )\n",
    "        #print (spiral.shape)\n",
    "        spiral[:, 3: ]=torch.clamp(spiral[:, 3: ], 0, 1) \n",
    "        \n",
    "        #print (\"#### length spiral \", get_length(spiral), spiral.shape, i)\n",
    "        \n",
    "    S1=get_length(spiral)\n",
    "    \n",
    "    \n",
    "    #print (\"Size of spiral; \", S1)\n",
    "    plt.imshow (spiral[:S1, 3:3+S1],interpolation='none')\n",
    "    plt.show()     \n",
    "    \n",
    "    plt.plot (spiral[:, 0])\n",
    "    plt.plot (spiral[:, 1])\n",
    "    plt.plot (spiral[:, 2])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow (spiral[:S1, :3],interpolation='none')\n",
    "    plt.show()     \n",
    "   \n",
    "        \n",
    "    \n",
    "    G_res, data_res, y_data_pred =construct_xyz_and_graph (spiral.permute(1,0),\n",
    "                                     fname_root=fname_root,\n",
    "                                                    label='Spiral', #limits=[X_min*1.2, X_max*1.2],\n",
    "                                                    dist_matrix=True,\n",
    "                                                  )\n",
    "    \n",
    "    if visualize:\n",
    "        \n",
    "        plt.imshow (spiral[:, 3:],interpolation='none')\n",
    "        plt.show()\n",
    "    #x(t) = rcos(t), y(t) = rsin(t), z(t) = at,\n",
    "    \n",
    "    return spiral\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bda41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, G_res, data_res,y_data= generate_sample_cond (GWebT,\n",
    "                cond=[-0.7255, -0.2038,  0.5942,  0.3315,  0.1786,  0.1852,  0.0122],#[-.5, 0.7, 0.6, 0.2, 0.3, 0.4, -0.9],\n",
    "                cond_scales=[1.,  ], #list of cond scales - each sampled...\n",
    "                flag=9992,\n",
    "              clamp=True, corplot=True,show_neighbors=True,\n",
    "            xyz_and_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d3ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76543ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow (output[:,3:])\n",
    "plt.show()\n",
    "\n",
    "get_length (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5a4e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "                      \n",
    "output=stack_and_extend (output.clone(), output.clone(), 10, 100,60,50,  #\n",
    "                     fname_root='file_name',\n",
    "                      visualize=True,\n",
    "                      make_graph = True,\n",
    "                                            \n",
    "                     )#{max_neighbors, xyz+max_neighbors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775bb1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.clone().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiral=make_spiral (output, radius=10, \n",
    "                 slope_z=5, delta_angle= 10/360*2*math.pi, steps=50,  \n",
    "                stagger_fraction = 0.5,\n",
    "                fname_root='spiral_transf_distmap_215_1',shuffle=True,\n",
    "                    avg_pos_in_overlap=False,\n",
    "                )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
